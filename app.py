from flask import Flask, request, jsonify
from flask_cors import CORS
import openai, asyncio, tempfile, base64, os, traceback  # æ·»åŠ  traceback
import edge_tts
import nest_asyncio

# ä¿®å¤å¼‚æ­¥äº‹ä»¶å¾ªç¯å†²çª
nest_asyncio.apply()

openai.api_key = os.environ.get("OPENAI_API_KEY")

app = Flask(__name__)
CORS(app)

@app.route('/')
def health_check():
    return "Voice Assistant API is running", 200

async def text_to_speech(text):
    communicate = edge_tts.Communicate(text, "zh-CN-XiaoxiaoNeural")
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as f:
        await communicate.save(f.name)
        with open(f.name, "rb") as audio_file:
            return base64.b64encode(audio_file.read()).decode("utf-8")

@app.route("/chat", methods=["POST"])
def chat():
    # æ•´ä¸ªè·¯ç”±é€»è¾‘æ”¾åœ¨ try-except å—ä¸­
    try:
        print("ğŸ“¥ æ”¶åˆ°è¯­éŸ³ä¸Šä¼ è¯·æ±‚")

        if 'audio' not in request.files:
            return jsonify({"error": "No audio uploaded"}), 400

        audio_file = request.files['audio']
        
        # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶å¤„ç†
        with tempfile.NamedTemporaryFile(suffix=".wav") as tmp_audio:
            audio_file.save(tmp_audio.name)
            
            # è¯­éŸ³è¯†åˆ«
            transcript = openai.Audio.transcribe("whisper-1", open(tmp_audio.name, "rb"))
            question = transcript["text"]
            print("ğŸ§  Whisper è¯†åˆ«å†…å®¹ï¼š", question)

            # GPTå¯¹è¯
            chat_response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªè¯­éŸ³åŠ©æ‰‹"},
                    {"role": "user", "content": question}
                ]
            )
            answer = chat_response["choices"][0]["message"]["content"]
            print("ğŸ¤– GPT å›å¤ï¼š", answer)

            # æ–‡æœ¬è½¬è¯­éŸ³
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                audio_base64 = loop.run_until_complete(text_to_speech(answer))
            finally:
                loop.close()
                
            return jsonify({"text": answer, "audio_base64": audio_base64})
    
    # ç‰¹å®šOpenAIé”™è¯¯å¤„ç†
    except openai.error.AuthenticationError:
        return jsonify({"error": "Invalid OpenAI API key"}), 401
    except openai.error.RateLimitError:
        return jsonify({"error": "OpenAI API rate limit exceeded"}), 429
    
    # é€šç”¨é”™è¯¯å¤„ç†
    except Exception as e:
        # æ‰“å°å®Œæ•´å †æ ˆè·Ÿè¸ªåˆ°æ§åˆ¶å°
        traceback.print_exc()
        
        # è¿”å›ç®€åŒ–é”™è¯¯ä¿¡æ¯ç»™å®¢æˆ·ç«¯
        return jsonify({
            "error": "Internal server error",
            "message": str(e)
        }), 500

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 10000))
    app.run(host="0.0.0.0", port=port)
